{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import random as rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done preprocessing\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nnScript.py:32: RuntimeWarning: overflow encountered in power\n",
      "  return  1/(1.0+math.e**-z) #your code here\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (39760,) (39700,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c9031b765aef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'timeit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnnScript\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Bill\\Desktop\\CSE474assignment1\\basecode\\nnScript.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[0mopts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'maxiter'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m}\u001b[0m    \u001b[1;31m# Preferred value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m \u001b[0mnn_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnnObjFunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitialWeights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'CG'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"minimized\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;31m#In Case you want to use fmin_cg, you may have to split the nnObjectFunction to two functions nnObjFunctionVal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Bill\\Anaconda\\lib\\site-packages\\scipy\\optimize\\_minimize.pyc\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_powell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'cg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'bfgs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Bill\\Anaconda\\lib\\site-packages\\scipy\\optimize\\optimize.pyc\u001b[0m in \u001b[0;36m_minimize_cg\u001b[1;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[0;32m   1159\u001b[0m             \u001b[0malpha_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgfkp1\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m                      _line_search_wolfe12(f, myfprime, xk, pk, gfk, old_fval,\n\u001b[1;32m-> 1161\u001b[1;33m                                           old_old_fval, c2=0.4)\n\u001b[0m\u001b[0;32m   1162\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0m_LineSearchError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m             \u001b[1;31m# Line search failed to find a better solution.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Bill\\Anaconda\\lib\\site-packages\\scipy\\optimize\\optimize.pyc\u001b[0m in \u001b[0;36m_line_search_wolfe12\u001b[1;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)\u001b[0m\n\u001b[0;32m    688\u001b[0m     ret = line_search_wolfe1(f, fprime, xk, pk, gfk,\n\u001b[0;32m    689\u001b[0m                              \u001b[0mold_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 690\u001b[1;33m                              **kwargs)\n\u001b[0m\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Bill\\Anaconda\\lib\\site-packages\\scipy\\optimize\\linesearch.pyc\u001b[0m in \u001b[0;36mline_search_wolfe1\u001b[1;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, args, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[0;32m     94\u001b[0m     stp, fval, old_fval = scalar_search_wolfe1(\n\u001b[0;32m     95\u001b[0m             \u001b[0mphi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mderphi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mderphi0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             c1=c1, c2=c2, amax=amax, amin=amin, xtol=xtol)\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Bill\\Anaconda\\lib\\site-packages\\scipy\\optimize\\linesearch.pyc\u001b[0m in \u001b[0;36mscalar_search_wolfe1\u001b[1;34m(phi, derphi, phi0, old_phi0, derphi0, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb'FG'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0malpha1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m             \u001b[0mphi1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m             \u001b[0mderphi1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mderphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Bill\\Anaconda\\lib\\site-packages\\scipy\\optimize\\linesearch.pyc\u001b[0m in \u001b[0;36mphi\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mfc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mderphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (39760,) (39700,) "
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "import nnScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "z_array = np.linspace(0,50,51)\n",
    "delta = np.linspace(0,9,10)\n",
    "n_class = 10\n",
    "print np.array([-1 * delta[l] * z_array[j] for l in xrange(n_class) for j in xrange(len(z_array))]).reshape((n_class, len(z_array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mat = loadmat('mnist_all.mat')\n",
    "test0 = mat['train2']\n",
    "singleNum = test0[1]\n",
    "singleNum = singleNum.reshape(28,28)\n",
    "\n",
    "img = zeros((28,28,3))\n",
    "img[:,:, 0] = singleNum\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Stack all training matrices into one 60000 × 784 matrix. Do the same for test matrices.\n",
    "2. Create a 60000 length vector with true labels (digits) for each training example. Same for test data.\n",
    "3. Normalize the training matrix and test matrix so that the values are between 0 and 1.\n",
    "4. Randomly split the 60000 × 784 normalized matrix into two matrices: training matrix (50000 × 784)\n",
    "and validation matrix (10000 × 784). Make sure you split the true labels vector into two parts as well.\n",
    "5. Feature selection - see next subsection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = loadmat('mnist_all.mat')\n",
    "test0 = mat['test0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "concatenate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = loadmat('mnist_all.mat')\n",
    "\n",
    "train_data = empty((50000,784))\n",
    "train_label = empty((50000,1))\n",
    "validation_data = empty((10000,784))\n",
    "validation_label = empty((10000, 1))\n",
    "test_data = empty((0,784))\n",
    "test_label = empty((0,1))\n",
    "    \n",
    "    \n",
    "#testing = empty((0,784))\n",
    "#testing_label = empty((0,1))\n",
    "training = empty((0,784))\n",
    "training_label = empty((0,1))\n",
    "test = \"test\"\n",
    "for i in xrange(10):\n",
    "    testArr = mat[test + str(int(i))]\n",
    "    length = len(testArr)\n",
    "    labels = ones((length, 1)) * i\n",
    "    test_label = concatenate((test_label, labels))\n",
    "    test_data = concatenate((test_data, testArr))\n",
    "print \"\\n\", test_data.shape\n",
    "print testing_label.shape\n",
    "\n",
    "train = \"train\"\n",
    "for i in xrange(10):\n",
    "    trainArr = mat[train + str(int(i))]\n",
    "    length = len(trainArr)\n",
    "    labels = ones((length, 1)) * i\n",
    "    training = concatenate((training, trainArr))\n",
    "    training_label = concatenate((training_label, labels))\n",
    "print \"\\n\", training.shape\n",
    "print training_label.shape\n",
    "\n",
    "test_data = test_data/255\n",
    "training = training/255  \n",
    "\n",
    "#testing = concatenate((testing, testing_label), axis = 1)\n",
    "#training = concatenate((training, training_label), axis = 1)\n",
    "#print \"\\n\", testing.shape\n",
    "#print training.shape\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_indecies = rand.sample(xrange(60000), 50000)\n",
    "training_indecies = sorted(training_indecies)\n",
    "validation_indecies = []\n",
    "offset = 0\n",
    "try:\n",
    "    for i in range(60000):\n",
    "        if training_indecies[i - offset] != i:\n",
    "            offset += 1\n",
    "            validation_indecies.append(i)\n",
    "except:\n",
    "    #print i\n",
    "    #print training_indecies\n",
    "    #print validation_indecies\n",
    "    for x in range(i, 60000):\n",
    "        validation_indecies.append(x)\n",
    "print \"done\"\n",
    "#print training_indecies\n",
    "#print validation_indecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get data into return arrays\n",
    "#train_data\n",
    "#train_label\n",
    "#validation_data\n",
    "#validation_label\n",
    "\n",
    "for i in range(50000):\n",
    "    new_data = training[training_indecies[i]].reshape(1,784)\n",
    "    new_label = training_label[training_indecies[i]].reshape(1,1)\n",
    "    train_data[i] = new_data\n",
    "    train_label[i] = new_label\n",
    "\n",
    "for i in range(10000):\n",
    "    new_data = training[validation_indecies[i]].reshape(1,784)\n",
    "    new_label = training_label[validation_indecies[i]].reshape(1,1)\n",
    "    validation_data[i] = new_data\n",
    "    validation_label[i] = new_label\n",
    "print \"done preprocessing\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = array([1,2,3])\n",
    "b = array([4,5,6])\n",
    "ab = zeros((2,3))\n",
    "ab[0] = a\n",
    "ab[1] = b\n",
    "print ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    \"\"\" Input:\n",
    "     Although this function doesn't have any input, you are required to load\n",
    "     the MNIST data set from file 'mnist_all.mat'.\n",
    "\n",
    "     Output:\n",
    "     train_data: matrix of training set. Each row of train_data contains \n",
    "       feature vector of a image\n",
    "     train_label: vector of label corresponding to each image in the training\n",
    "       set\n",
    "     validation_data: matrix of training set. Each row of validation_data \n",
    "       contains feature vector of a image\n",
    "     validation_label: vector of label corresponding to each image in the \n",
    "       training set\n",
    "     test_data: matrix of training set. Each row of test_data contains \n",
    "       feature vector of a image\n",
    "     test_label: vector of label corresponding to each image in the testing\n",
    "       set\n",
    "\n",
    "     Some suggestions for preprocessing step:\n",
    "     - divide the original data set to training, validation and testing set\n",
    "           with corresponding labels\n",
    "     - convert original data set from integer to double by using double()\n",
    "           function\n",
    "     - normalize the data to [0, 1]\n",
    "     - feature selection\"\"\"\n",
    "    \n",
    "    mat = loadmat('mnist_all.mat')\n",
    "\n",
    "    train_data = np.empty((50000,784))\n",
    "    train_label = np.empty((50000,1))\n",
    "    validation_data = np.empty((10000,784))\n",
    "    validation_label = np.empty((10000, 1))\n",
    "    test_data = np.empty((0,784))\n",
    "    test_label = np.empty((0,1))\n",
    "\n",
    "\n",
    "    #testing = empty((0,784))\n",
    "    #testing_label = empty((0,1))\n",
    "    training = np.empty((0,784))\n",
    "    training_label = np.empty((0,1))\n",
    "    test = \"test\"\n",
    "    for i in xrange(10):\n",
    "        testArr = mat[test + str(int(i))]\n",
    "        length = len(testArr)\n",
    "        labels = np.ones((length, 1)) * i\n",
    "        test_label = np.concatenate((test_label, labels))\n",
    "        test_data = np.concatenate((test_data, testArr))\n",
    "    print \"\\n\", test_data.shape\n",
    "    print test_label.shape\n",
    "\n",
    "    train = \"train\"\n",
    "    for i in xrange(10):\n",
    "        trainArr = mat[train + str(int(i))]\n",
    "        length = len(trainArr)\n",
    "        labels = np.ones((length, 1)) * i\n",
    "        training = np.concatenate((training, trainArr))\n",
    "        training_label = np.concatenate((training_label, labels))\n",
    "    print \"\\n\", training.shape\n",
    "    print training_label.shape\n",
    "\n",
    "    test_data = test_data/255\n",
    "    training = training/255\n",
    "    \n",
    "    training_indecies = rand.sample(xrange(60000), 50000)\n",
    "    training_indecies = sorted(training_indecies)\n",
    "    validation_indecies = []\n",
    "    offset = 0\n",
    "    try:\n",
    "        for i in range(60000):\n",
    "            if training_indecies[i - offset] != i:\n",
    "                offset += 1\n",
    "                validation_indecies.append(i)\n",
    "    except:\n",
    "        #print i\n",
    "        #print training_indecies\n",
    "        #print validation_indecies\n",
    "        for x in range(i, 60000):\n",
    "            validation_indecies.append(x)\n",
    "            \n",
    "\n",
    "    for i in range(50000):\n",
    "        new_data = training[training_indecies[i]].reshape(1,784)\n",
    "        new_label = training_label[training_indecies[i]].reshape(1,1)\n",
    "        train_data[i] = new_data\n",
    "        train_label[i] = new_label\n",
    "\n",
    "    for i in range(10000):\n",
    "        new_data = training[validation_indecies[i]].reshape(1,784)\n",
    "        new_label = training_label[validation_indecies[i]].reshape(1,1)\n",
    "        validation_data[i] = new_data\n",
    "        validation_label[i] = new_label\n",
    "    print \"done preprocessing\"\n",
    "    \n",
    "    print train_data, \"\\n\\n\", train_label, \"\\n\\n\", validation_data, \"\\n\\n\", validation_label, \"\\n\\n\", test_data, \"\\n\\n\", test_label\n",
    "    return train_data, train_label, validation_data, validation_label, test_data, test_label\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"# Notice that z can be a scalar, a vector or a matrix\n",
    "    # return the sigmoid of input z\"\"\"\n",
    "    \n",
    "    return  1/(1.0+math.e**-z) #your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feedforward_prop(input_array, w1, w2, n_hidden, n_class): #for a single training/validation/test entry\n",
    "    a_array = np.zeros((n_hidden))\n",
    "    z_array = np.zeros((n_hidden))\n",
    "    b_array = np.zeros((n_class))\n",
    "    o_array = np.zeros((n_class))\n",
    "    #calculate a_array values\n",
    "    for j in xrange(n_hidden):\n",
    "        for i in xrange(len(input_array + 1)):\n",
    "            a_array[j] += w1[j,i]*input_array[i]\n",
    "    #for j in range(n_hidden):\n",
    "    z_array = sigmoid(a_array)\n",
    "    \n",
    "    for l in range(n_class):\n",
    "        for j in range(n_hidden):\n",
    "            b_array[l] += w2[l,j]*z_array[j]\n",
    "    o_array = sigmoid(b_array)\n",
    "    return o_array, z_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test feedforward_prop\n",
    "w1 = array([[.1,.4],[.2,.5],[.3,.6]])\n",
    "w2 = array([[.1,.3,.5],[.2,.4,.6]])\n",
    "input_array = array([.2,.4])\n",
    "n_hidden = 3\n",
    "n_class = 2\n",
    "feedforward_prop(input_array, w1, w2, n_hidden, n_class)\n",
    "#IT WORKS!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def error_func(output_array, y, n_class):\n",
    "    yp = np.array([y == i for i in range(n_class)], dtype = int)\n",
    "    return .5*sum((yp - output_array)**2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = 8\n",
    "output_array = array([0,0,0,0,0,1,0,0,0,0])\n",
    "yp = np.array([y == i for i in range(10)], dtype = float)\n",
    "print error_func(output_array, y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_delta(y, output_array, n_class):\n",
    "    yp = np.array([y == i for i in range(n_class)], dtype = int)\n",
    "    delta = (yp - output_array)*(1-output_array)*output_array\n",
    "    return delta\n",
    "    #print \"yp = \", yp\n",
    "    #print \"OA = \", output_array\n",
    "    #print \"yp-oa =\", yp - output_array\n",
    "    #print \"1 - OA = \", 1 - output_array\n",
    "    #print (yp - output_array)*(1-output_array)\n",
    "    #print (yp - output_array)*(1-output_array)*output_array\n",
    "\n",
    "def calc_grad2(z_array, n_class):\n",
    "    #J_grad = zeros((len(input_array), n_class))\n",
    "    delta = calc_delta(y,output_array, n_class)\n",
    "    J_grad2 =  array([-1 * delta[l] * z_array[j] for l in xrange(n_class) for j in xrange(len(z_array))]) \n",
    "    return J_grad2\n",
    "\n",
    "def calc_grad1(input_array, w2, delta, n_class):\n",
    "    J_grad1 = array([-(1-z_array[j]*z_array[j]*sum(delta*w2[j])*input_array[i]) for j in xrange(len(input_array)) for i in xrange(len(input_array))])\n",
    "    return J_grad1\n",
    "#obj_grad return val is sum of J_grad1 over all training data *1/n (n=num training examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = 8\n",
    "yp = np.array([y == i for i in range(10)], dtype = float)\n",
    "output_array = array([0,0,0,0,0,1,0,0,0,0])\n",
    "calc_delta(y, output_array, 10)\n",
    "print - calc_delta(y, output_array,10) * yp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([[4,5,6],[1,2,3]])\n",
    "print sum(a*b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nnScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "J_grad1 = np.array([-1*(1-z_array[j])*z_array[j]*sum(delta*w2[:,j])*input_array[i] for j in xrange(w2.shape[0]) for i in xrange(input_array.shape[0])]).reshape((w2.shape[0], input_array.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = array([[1,2,3],[4,5,6]])\n",
    "print a*a\n",
    "print sum(a*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = linspace(0,9,10)\n",
    "print d\n",
    "d+=d\n",
    "print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
